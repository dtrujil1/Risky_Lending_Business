---
title: "Data Preparation & Cleaning"
output: github_document
---

```{r setup, include=F}
knitr::opts_chunk$set(
  fig.path = "markdown_figs/data_preparation-"
)
```

```{r message=F}
library(magrittr)
library(dplyr)
library(ggplot2)
library(glmnet)
library(randomForest)
library(caret)
library(data.table)
library(doParallel)

registerDoParallel(6)
```

## Loading the dataset

```{r}
loan_df <- fread("data/train_v3.csv")
```

## Cleaning The Data Up

### Recoding The Target Variable

```{r}
loss <- loan_df %>%
  select(loss) %>%
  mutate_at(c("loss"), ~ifelse(. > 0, 1, 0)) %>%
  mutate_at(c("loss"), as.factor)
```

### Removing Near Zero Variance Variables

```{r}
nzv_df <- nearZeroVar(loan_df, saveMetrics = T, allowParallel = T)
loan_df_cln <- loan_df[!nzv_df$nzv]
```

### Quick Inputation of `NA`s

```{r}
impute_model <- preProcess(loan_df_cln, method = "medianImpute")
loan_df_cln2 <- predict(impute_model, loan_df_cln)
```

### Preparing The Data for Feature Selection

```{r}
loan_df_cln3 <- loan_df_cln2 %>% select(-c("X", "id"))

predictor_vars <- data.matrix(loan_df_cln3)

loss <- loss %>% use_series("loss") %>% as.vector()
```

## Feature Selection and Extraction

### Selecting Features using LASSO

```{r}
set.seed(2019)

cv_fit <- cv.glmnet(
  predictor_vars, loss,
  type.measure = "class",
  family = "binomial",
  alpha = 1,
  parallel = T
)
```

```{r}
plot(cv_fit)
```

```{r}
lasso_model <- glmnet(
  predictor_vars, loss,
  lambda = cv_fit$lambda.min,
  family = "binomial",
  alpha = 1
)
```

```{r}
coeff_matrix <- coef(lasso_model, s = "lambda.min")

coeff_matrix
```

```{r}
lasso_coefs <- data.frame(
  name = coeff_matrix@Dimnames[[1]][coeff_matrix@i + 1],
  coefficient = coeff_matrix@x
  ) %>%
  filter(name !="(Intercept)") %>%
  use_series("name") %>%
  as.character()

lasso_coefs
```

#### Separating Good Predictor Variables from the Noise

```{r}
good_pred_var <- loan_df_cln3 %>% select(lasso_coefs)

head(good_pred_var)
```

```{r}
noise_pred_var <- loan_df_cln3 %>% select(-lasso_coefs)

head(noise_pred_var)
```

#### Applying PCA to compresss Noisy Predictor Variables

```{r}

pca_model <- preProcess(noise_pred_var, method=c( "center", "scale", "pca"))
pca_df <- predict(pca_model, noise_pred_var)

head(pca_df)
```

```{r}
compressed_df <- cbind(good_pred_var, pca_df, loss)

head(compressed_df)
```

#### Building a Model

```{r}
set.seed(2019)

train_index <- createDataPartition(
  compressed_df$loss,
  p = 0.8,
  list = F,
  times = 1
)

train_data <- compressed_df[train_index,]
val_data <- compressed_df[-train_index,]
```

```{r}
model_fit <- train(target_var ~ ., data = train_data, method = "parRF")
```
