---
title: "Data Preparation & Cleaning"
output: github_document
---

```{r setup, include=F}
knitr::opts_chunk$set(
  fig.path = "markdown_figs/data_preparation-"
)
```

```{r message=F}
library(magrittr)
library(dplyr)
library(ggplot2)
library(glmnet)
library(randomForest)
library(caret)
library(data.table) # faster reading speeds for csv files (fread)
library(doParallel)
library(klaR) # for stepwise (stepclass function)
```

## Loading the dataset

```{r}
loan_dt <- fread("data/train_v3.csv")
loan_df <- as.data.frame(loan_dt)
```

## Cleaning The Data Up

### Recoding The Predictor Variables

```{r}
loan_df <- loan_df %>% mutate_all(as.numeric)
```

### Recoding The Target Variable

```{r}
target_var <- loan_df %>%
  select(loss) %>%
  mutate_at(c("loss"), ~ifelse(. > 0, 1, 0)) %>%
  mutate_at(c("loss"), as.factor)
```

### Removing Near Zero Variance Variables

```{r}
registerDoParallel(6)

nzv_cols <- nearZeroVar(loan_df, allowParallel = T, foreach = T)
loan_df_cln <- loan_df[, -nzv_cols]
```

### Quick Inputation of `NA`s

```{r}
impute_model <- preProcess(loan_df_cln, method = "medianImpute")
loan_df_cln2 <- predict(impute_model, loan_df_cln)
```

```{r}
anyNA(loan_df_cln2)
```

### Preparing The Data for Feature Selection

```{r}
loan_df_cln3 <- loan_df_cln2 %>% select(-c("V1", "id"))

predictor_vars <- data.matrix(loan_df_cln3)

loss <- target_var %>% use_series("loss") %>% as.vector()
```

## Feature Selection and Extraction

### Selecting Features using LASSO

```{r}
set.seed(2019)
registerDoParallel(6)

cv_fit <- cv.glmnet(
  predictor_vars, loss,
  type.measure = "class",
  family = "binomial",
  alpha = 1,
  parallel = T
)
```

```{r}
plot(cv_fit)
```

```{r}
lasso_model <- glmnet(
  predictor_vars, loss,
  lambda = cv_fit$lambda.min,
  family = "binomial",
  alpha = 1
)
```

```{r}
plot(lasso_model, xvar="lambda", label=TRUE)
```

```{r}
coeff_matrix <- coef(lasso_model, s = "lambda.min")

coeff_matrix
```

```{r}
lasso_coefs <- data.frame(
  name = coeff_matrix@Dimnames[[1]][coeff_matrix@i + 1],
  coefficient = coeff_matrix@x
  ) %>%
  filter(name !="(Intercept)") %>%
  use_series("name") %>%
  as.character()

lasso_coefs
```

#### Separating Good Predictor Variables from the Noise

```{r}
good_pred_var <- loan_df_cln3 %>% select(lasso_coefs)

head(good_pred_var)
```

```{r}
noise_pred_var <- loan_df_cln3 %>% select(-lasso_coefs)

head(noise_pred_var)
```

#### Applying PCA to compresss Noisy Predictor Variables

```{r}
pca_model <- preProcess(
  noise_pred_var,
  method = c( "center", "scale", "pca"),
  pcaComp = 10
)
pca_df <- predict(pca_model, noise_pred_var)

head(pca_df)
```

#### Building a Model

```{r}
compressed_df <- cbind(good_pred_var, loss)

head(compressed_df)
```

## Spliting data into Training and Validation

```{r}
set.seed(2019)

train_index <- createDataPartition(
  compressed_df$loss,
  p = 0.8,
  list = F,
  times = 1
)

train_data <- compressed_df[train_index,]
val_data <- compressed_df[-train_index,]
```

## Stepwise Variable Selection for Classification

```{r}
# step_model <- stepclass(loss ~ ., data = train_data, method = "lcd", direction = "backward")
```

## Building a Random Forest Model for Classification

```{r}
registerDoParallel(6)

model_rf <- train(loss ~ ., data = train_data, method = "parRF")
```
